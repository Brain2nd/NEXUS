# SNNTorch: Pure SNN Floating-Point Arithmetic

**100% çº¯è„‰å†²ç¥ç»ç½‘ç»œæµ®ç‚¹è¿ç®—åº“**

åŸºäº Integrate-and-Fire (IF) ç¥ç»å…ƒå®ç°çš„å®Œæ•´æµ®ç‚¹è¿ç®—ç³»ç»Ÿï¼Œæ‰€æœ‰è®¡ç®—å‡åœ¨è„‰å†²åŸŸå†…å®Œæˆã€‚

## âœ¨ ç‰¹æ€§

- ğŸ§  **100% çº¯ SNN**: æ‰€æœ‰è¿ç®—ä½¿ç”¨ IF ç¥ç»å…ƒé—¨ç”µè·¯ï¼Œæ— ä¼ ç»Ÿæ•°å€¼è®¡ç®—
- ğŸ¯ **100% å¯¹é½ PyTorch**: FP32 ç´¯åŠ æ¨¡å¼ä¸ `nn.Linear` å®Œå…¨ä¸€è‡´
- ğŸ“ **å¤šç²¾åº¦æ”¯æŒ**: FP8 E4M3 / FP16 / FP32 ç´¯åŠ ç²¾åº¦å¯é€‰
- ğŸ”§ **ä»»æ„ç»´åº¦**: ç¼–ç å™¨/è§£ç å™¨æ”¯æŒä»»æ„å¼ é‡å½¢çŠ¶
- âš¡ **é«˜æ•ˆå®ç°**: åŸºäº SpikingJelly æ¡†æ¶ä¼˜åŒ–

## ğŸ—ï¸ æ¶æ„

```
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚           çº¯ SNN è®¡ç®—åŸŸ                  â”‚
                    â”‚                                         â”‚
ANN æµ®ç‚¹è¾“å…¥ â”€â”€â†’ [ç¼–ç å™¨] â”€â”€â†’ [SNN è¿ç®—] â”€â”€â†’ [è§£ç å™¨] â”€â”€â†’ ANN æµ®ç‚¹è¾“å‡º
                    â”‚           â†‘                             â”‚
                    â”‚     é—¨ç”µè·¯ç»„æˆ:                          â”‚
                    â”‚     â€¢ AND/OR/XOR/NOT é—¨                 â”‚
                    â”‚     â€¢ åŠåŠ å™¨/å…¨åŠ å™¨                      â”‚
                    â”‚     â€¢ è¡Œæ³¢è¿›ä½åŠ æ³•å™¨                     â”‚
                    â”‚     â€¢ é˜µåˆ—ä¹˜æ³•å™¨                         â”‚
                    â”‚     â€¢ æ¡¶å½¢ç§»ä½å™¨                         â”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸ“¦ ç»„ä»¶

### è¾¹ç•Œç»„ä»¶ (ANN â†” SNN)

| ç»„ä»¶ | åŠŸèƒ½ | è¾“å…¥ â†’ è¾“å‡º |
|------|------|-------------|
| `PulseFloatingPointEncoder` | æµ®ç‚¹â†’è„‰å†² | `[...]` â†’ `[..., 8]` |
| `PulseFloatingPointDecoder` | è„‰å†²â†’æµ®ç‚¹ | `[..., 8]` â†’ `[...]` |

### æ ¸å¿ƒé—¨ç”µè·¯

| ç»„ä»¶ | å…¬å¼ | IF ç¥ç»å…ƒæ•° |
|------|------|-------------|
| `ANDGate` | `H(A + B - 1.5)` | 1 |
| `ORGate` | `H(A + B - 0.5)` | 1 |
| `XORGate` | `(A + B) - 2Ã—AND(A,B)` | 2 |
| `NOTGate` | `H(1 - A - 0.5)` | 1 |
| `FullAdder` | `S = AâŠ•BâŠ•C, Cout = ...` | 7 |

### æµ®ç‚¹è¿ç®—

| ç»„ä»¶ | åŠŸèƒ½ | ç²¾åº¦ |
|------|------|------|
| `SpikeFP8Multiplier` | FP8 Ã— FP8 â†’ FP8 | 8-bit |
| `SpikeFP8Adder_Spatial` | FP8 + FP8 â†’ FP8 | 8-bit |
| `SpikeFP16Adder` | FP16 + FP16 â†’ FP16 | 16-bit |
| `SpikeFP32Adder` | FP32 + FP32 â†’ FP32 | 32-bit |
| `SpikeFP8Linear_MultiPrecision` | å…¨è¿æ¥å±‚ | å¯é€‰ |

## ğŸš€ å¿«é€Ÿå¼€å§‹

### å®‰è£…ä¾èµ–

```bash
pip install torch spikingjelly
```

### åŸºæœ¬ä½¿ç”¨

```python
import torch
from SNNTorch.atomic_ops import (
    PulseFloatingPointEncoder,
    PulseFloatingPointDecoder,
    SpikeFP8Linear_MultiPrecision
)

# 1. åˆ›å»ºç¼–ç å™¨/è§£ç å™¨
encoder = PulseFloatingPointEncoder()
decoder = PulseFloatingPointDecoder()

# 2. ç¼–ç æµ®ç‚¹æ•°ä¸ºè„‰å†²
x = torch.randn(32, 64)  # [batch, features]
x_pulse = encoder(x)      # [32, 64, 8]

# 3. çº¯ SNN è®¡ç®—
linear = SpikeFP8Linear_MultiPrecision(64, 32, accum_precision='fp32')
linear.set_weight_from_float(weight, encoder)
y_pulse = linear(x_pulse)  # [32, 32, 8]

# 4. è§£ç è„‰å†²ä¸ºæµ®ç‚¹æ•°
y = decoder(y_pulse)       # [32, 32]
```

### å¤šå±‚ç½‘ç»œ

```python
# æ„å»º 3 å±‚ SNN ç½‘ç»œ
layer1 = SpikeFP8Linear_MultiPrecision(128, 64, accum_precision='fp32')
layer2 = SpikeFP8Linear_MultiPrecision(64, 32, accum_precision='fp32')
layer3 = SpikeFP8Linear_MultiPrecision(32, 10, accum_precision='fp32')

# å‰å‘ä¼ æ’­ (å…¨ç¨‹è„‰å†²åŸŸ)
x_pulse = encoder(x)
h1 = layer1(x_pulse)
h2 = layer2(h1)
y_pulse = layer3(h2)
y = decoder(y_pulse)
```

## ğŸ“Š ç²¾åº¦å¯¹é½

ä¸ PyTorch `nn.Linear` çš„å¯¹é½æµ‹è¯•ç»“æœ:

| ç´¯åŠ ç²¾åº¦ | å¯¹é½ç‡ | è¯´æ˜ |
|----------|--------|------|
| FP8 | ~50% | æ¯æ­¥èˆå…¥ç´¯ç§¯è¯¯å·® |
| FP16 | ~95% | æ¥è¿‘ PyTorch è¡Œä¸º |
| **FP32** | **100%** | **å®Œå…¨å¯¹é½** |

## ğŸ”¬ æŠ€æœ¯ç»†èŠ‚

### FP8 E4M3 æ ¼å¼

```
[S | E3 E2 E1 E0 | M2 M1 M0]
 â†‘   \_________/   \_______/
ç¬¦å·    æŒ‡æ•°(4ä½)    å°¾æ•°(3ä½)

bias = 7
Normal:    value = (-1)^S Ã— 2^(E-7) Ã— (1 + M/8)
Subnormal: value = (-1)^S Ã— 2^(-6) Ã— (M/8)
```

### çº¯ SNN åŸåˆ™

æ‰€æœ‰æ ¸å¿ƒè¿ç®—**ä»…ä½¿ç”¨**:
- âœ… IF ç¥ç»å…ƒ (é˜ˆå€¼ + å¤ä½)
- âœ… å…´å¥‹æ€§/æŠ‘åˆ¶æ€§çªè§¦æƒé‡
- âœ… è„‰å†² (0/1) ä¿¡å·

**ç¦æ­¢ä½¿ç”¨**:
- âŒ Python ç®—æœ¯è¿ç®— (`+`, `-`, `*`, `/`)
- âŒ æ¯”è¾ƒè¿ç®—ç¬¦ (`>`, `<`, `>=`)
- âŒ é«˜çº§å¼ é‡æ“ä½œ (`.sum()`, `.clamp()`)

## ğŸ“ ç›®å½•ç»“æ„

```
SNNTorch/
â”œâ”€â”€ atomic_ops/
â”‚   â”œâ”€â”€ __init__.py              # æ¨¡å—å¯¼å‡º
â”‚   â”œâ”€â”€ logic_gates.py           # åŸºç¡€é€»è¾‘é—¨ (IF ç¥ç»å…ƒ)
â”‚   â”œâ”€â”€ logic_gates_lif.py       # LIF ç‰ˆæœ¬é€»è¾‘é—¨ (ç‰©ç†æ¨¡æ‹Ÿ)
â”‚   â”œâ”€â”€ floating_point.py        # FP8 ç¼–ç å™¨
â”‚   â”œâ”€â”€ pulse_decoder.py         # FP8/16/32 è§£ç å™¨
â”‚   â”œâ”€â”€ fp8_mul.py               # FP8 ä¹˜æ³•å™¨
â”‚   â”œâ”€â”€ fp8_mul_to_fp32.py       # FP8â†’FP32 é«˜ç²¾åº¦ä¹˜æ³•å™¨
â”‚   â”œâ”€â”€ fp8_adder_spatial.py     # FP8 åŠ æ³•å™¨
â”‚   â”œâ”€â”€ fp16_components.py       # FP8â†”FP16 è½¬æ¢å™¨
â”‚   â”œâ”€â”€ fp16_adder.py            # FP16 åŠ æ³•å™¨
â”‚   â”œâ”€â”€ fp32_components.py       # FP8â†”FP32 è½¬æ¢å™¨
â”‚   â”œâ”€â”€ fp32_adder.py            # FP32 åŠ æ³•å™¨
â”‚   â”œâ”€â”€ fp8_linear_multi.py      # å¤šç²¾åº¦ Linear å±‚
â”‚   â””â”€â”€ ...
â”œâ”€â”€ tests/
â”‚   â”œâ”€â”€ test_suite.py            # æ ¸å¿ƒæµ‹è¯•å¥—ä»¶
â”‚   â”œâ”€â”€ test_all_precision_alignment.py  # 100% å¯¹é½æµ‹è¯•
â”‚   â”œâ”€â”€ test_robustness.py       # ç‰©ç†é²æ£’æ€§æµ‹è¯•
â”‚   â””â”€â”€ ...
â””â”€â”€ models/
    â”œâ”€â”€ mnist_fp8_train.py       # MNIST è®­ç»ƒç¤ºä¾‹
    â””â”€â”€ mnist_snn_infer.py       # SNN æ¨ç†ç¤ºä¾‹
```

## ğŸ§ª è¿è¡Œæµ‹è¯•

### åŠŸèƒ½æ­£ç¡®æ€§æµ‹è¯•

```bash
python SNNTorch/tests/test_all_precision_alignment.py
```

é¢„æœŸè¾“å‡º:
```
âœ“ FP8 ç´¯åŠ :  100% å¯¹é½
âœ“ FP16 ç´¯åŠ : 100% å¯¹é½
âœ“ FP32 ç´¯åŠ : 100% å¯¹é½
```

### ç‰©ç†é²æ£’æ€§æµ‹è¯•

æ¨¡æ‹ŸçœŸå®ç¥ç»å½¢æ€ç¡¬ä»¶çš„éç†æƒ³ç‰¹æ€§ï¼š

```bash
python SNNTorch/tests/test_robustness.py
```

**æµ‹è¯•å†…å®¹**:

| å®éªŒ | å‚æ•° | è¯´æ˜ |
|------|------|------|
| Î² æ‰«æ | 0.01 - 1.0 | LIF ç¥ç»å…ƒè†œç”µä½æ³„æ¼ |
| Ïƒ æ‰«æ | 0.0 - 1.0 | è¾“å…¥é«˜æ–¯å™ªå£° |
| åŠ æ³•å™¨ | 4-bit RCA | å¤æ‚ç”µè·¯é²æ£’æ€§ |

**å…¸å‹ç»“æœ**:
```
Î² æ‰«æ: å³ä½¿ Î²=0.01ï¼ŒåŸºæœ¬é—¨ä»ä¿æŒ 100% æ­£ç¡®ç‡
Ïƒ æ‰«æ: Ïƒ<0.15 æ—¶ä¿æŒ >99% å‡†ç¡®ç‡
        Ïƒ>0.30 æ—¶å‡†ç¡®ç‡å¼€å§‹æ˜¾è‘—ä¸‹é™
```

## ğŸ“œ è®¸å¯è¯

MIT License

## ğŸ™ è‡´è°¢

- [SpikingJelly](https://github.com/fangwei123456/spikingjelly) - SNN æ¡†æ¶
- [PyTorch](https://pytorch.org/) - æ·±åº¦å­¦ä¹ æ¡†æ¶

---

**HumanBrain Project** - æ¢ç´¢ç±»è„‘è®¡ç®—çš„è¾¹ç•Œ

