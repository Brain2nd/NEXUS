@article{davies2018loihi,
  title   = {Loihi: A Neuromorphic Manycore Processor with On-Chip Learning},
  author  = {Davies, Mike and Srinivasa, Narayan and Lin, Tsung-Han and Chinya, Gautham and Cao, Yongqiang and Joshi, Sriharsha and Lines, Nabil and Wild, Adam and Wang, Hong and others},
  journal = {IEEE Micro},
  volume  = {38},
  number  = {1},
  pages   = {82--99},
  year    = {2018},
  doi     = {10.1109/MM.2018.112130359}
}
@article{tay2022efficient,
  title   = {Efficient Transformers: A Survey},
  author  = {Tay, Yi and Dehghani, Mostafa and Bahri, Dara and Metzler, Donald},
  journal = {ACM Computing Surveys},
  volume  = {55},
  number  = {6},
  year    = {2022},
  doi     = {10.1145/3530811}
}
@article{roy2019towards,
  title   = {Towards spike-based machine intelligence with neuromorphic computing},
  author  = {Roy, Kaushik and Jaiswal, Akhilesh and Panda, Priyadarshini},
  journal = {Nature},
  volume  = {575},
  number  = {7784},
  pages   = {607--617},
  year    = {2019},
  doi     = {10.1038/s41586-019-1677-2}
}
@article{davies2021loihi,
  title   = {Advancing Neuromorphic Computing with Loihi: A Survey of Results and Outlook},
  author  = {Davies, Mike and Wild, Adam and Orchard, Garrick and Sandamirskaya, Yulia and Fonseca Guerra, Gustavo A. and Joshi, Pallab and Plank, Philipp and Risbud, Shruti},
  journal = {Proceedings of the IEEE},
  volume  = {109},
  number  = {5},
  pages   = {911--934},
  year    = {2021},
  doi     = {10.1109/JPROC.2021.3067593}
}
@article{orchard2021loihi2,
  title   = {Efficient Neuromorphic Signal Processing with Loihi 2},
  author  = {Orchard, Garrick and Frady, Paxon E. and Brandstetter, Johannes and Davies, Mike and others},
  journal = {arXiv preprint arXiv:2111.03746},
  year    = {2021},
  url     = {https://arxiv.org/abs/2111.03746}
}
@inproceedings{zheng2021going,
  title     = {Going Deeper with Directly-Trained Larger Spiking Neural Networks},
  author    = {Zheng, Hanle and Wu, Yujie and Deng, Lei and Hu, Yifan and Li, Guoqi},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  volume    = {35},
  pages     = {11062--11070},
  year      = {2021},
  doi       = {10.1609/aaai.v35i12.17320}
}
@inproceedings{zhou2023spikformer,
  title     = {Spikformer: When Spiking Neural Network Meets Transformer},
  author    = {Zhou, Zhaokun and Zhu, Yuesheng and He, Chao and Wang, Yaowei and Yan, Shuicheng and Tian, Yonghong and Yuan, Li},
  booktitle = {International Conference on Learning Representations (ICLR)},
  year      = {2023},
  url       = {https://openreview.net/forum?id=frE4fUwz_h}
}
@article{zhu2023spikegpt,
  title   = {SpikeGPT: Generative Pre-trained Language Model with Spiking Neural Networks},
  author  = {Zhu, Rong and Zhao, Qihang and Eshraghian, Jason K.},
  journal = {arXiv preprint arXiv:2302.13939},
  year    = {2023},
  url     = {https://arxiv.org/abs/2302.13939}
}
@inproceedings{yao2023sdt,
  title     = {Spike-Driven Transformer},
  author    = {Yao, Man and Hu, Jiakui and Zhou, Zhaokun and Yuan, Li and Tian, Yonghong and Xu, Bo and Li, Guoqi},
  booktitle = {Advances in Neural Information Processing Systems (NeurIPS)},
  year      = {2023},
  url       = {https://papers.nips.cc/paper_files/paper/2023/file/ca0f5358dbadda74b3049711887e9ead-Paper-Conference.pdf}
}
@article{neftci2019surrogate,
  title   = {Surrogate Gradient Learning in Spiking Neural Networks: Bringing the Power of Gradient-Based Optimization to Spiking Neural Networks},
  author  = {Neftci, Emre O. and Mostafa, Hesham and Zenke, Friedemann},
  journal = {IEEE Signal Processing Magazine},
  volume  = {36},
  number  = {6},
  pages   = {51--63},
  year    = {2019},
  doi     = {10.1109/MSP.2019.2931595}
}
@article{wu2018stbp,
  title   = {Spatio-Temporal Backpropagation for Training High-Performance Spiking Neural Networks},
  author  = {Wu, Yujie and Deng, Lei and Li, Guoqi and Zhu, Jinyao and Shi, Luping},
  journal = {Frontiers in Neuroscience},
  volume  = {12},
  pages   = {331},
  year    = {2018},
  doi     = {10.3389/fnins.2018.00331}
}
@inproceedings{shrestha2018slayer,
  title     = {SLAYER: Spike Layer Error Reassignment in Time},
  author    = {Shrestha, Sumit B. and Orchard, Garrick},
  booktitle = {Advances in Neural Information Processing Systems (NeurIPS)},
  year      = {2018}
}
@article{auge2021encoding,
  title   = {A Survey of Encoding Techniques for Signal Processing in Spiking Neural Networks},
  author  = {Auge, Daniel and Hille, Julian and Mueller, Etienne and Knoll, Alois},
  journal = {Neural Processing Letters},
  volume  = {53},
  number  = {6},
  pages   = {4693--4710},
  year    = {2021},
  doi     = {10.1007/s11063-021-10562-2}
}
@article{guo2021coding,
  title   = {Neural Coding in Spiking Neural Networks: A Comparative Study for Robust Neuromorphic Systems},
  author  = {Guo, Wenzhe and Fouda, Mohammed E. and Eltawil, Ahmed M. and Salama, Khaled N.},
  journal = {Frontiers in Neuroscience},
  volume  = {15},
  pages   = {638474},
  year    = {2021},
  doi     = {10.3389/fnins.2021.638474}
}
@article{rueckauer2017conversion,
  title   = {Conversion of Continuous-Valued Deep Networks to Efficient Event-Driven Networks},
  author  = {Rueckauer, Bodo and Lungu, Iulia-Alexandra and Hu, Yuhuang and Pfeiffer, Michael and Liu, Shih-Chii},
  journal = {Frontiers in Neuroscience},
  volume  = {11},
  pages   = {682},
  year    = {2017},
  doi     = {10.3389/fnins.2017.00682}
}
@article{gao2023highaccuracy,
  title   = {High-Accuracy Deep ANN-to-SNN Conversion Using Quantization-Aware Training Framework and Calcium-Gated Bipolar Leaky Integrate-and-Fire Neuron},
  author  = {Gao, Kaidong and Liu, Xuhui and Ma, Zhixin and Zhang, Xinxin and others},
  journal = {Frontiers in Neuroscience},
  year    = {2023},
  note    = {Online first; add page/DOI when available},
  url     = {https://www.frontiersin.org/journals/neuroscience}
}
@article{bu2023ultralow,
  title   = {Optimal ANN-SNN Conversion for High-Accuracy and Ultra-Low-Latency Spiking Neural Networks},
  author  = {Bu, Tong and Fang, Wei and Ding, Jianhao and Dai, PengLin and Yu, Zhaofei and Huang, Tiejun},
  journal = {arXiv preprint arXiv:2303.04347},
  year    = {2023},
  url     = {https://arxiv.org/abs/2303.04347}
}
@article{bonilla2022ttfs,
  title   = {Analyzing Time-to-First-Spike Coding Schemes: A Theoretical Approach},
  author  = {Bonilla, Luis},
  journal = {Frontiers in Neuroscience},
  volume  = {16},
  pages   = {971937},
  year    = {2022},
  doi     = {10.3389/fnins.2022.971937}
}
@article{stanojevic2024ttfs,
  title   = {High-Performance Deep Spiking Neural Networks with 0.3 Spikes per Neuron},
  author  = {Stanojevi{\'c}, Ana and Wo{\'z}niak, Stanis{\l}aw and Bellec, Guillaume and Cherubini, Giovanni and Pantazi, Angeliki and Gerstner, Wulfram},
  journal = {Nature Communications},
  volume  = {15},
  pages   = {6793},
  year    = {2024},
  doi     = {10.1038/s41467-024-51110-5}
}
@article{you2024spikeziptf,
  title   = {SpikeZIP-TF: Conversion is All You Need for Transformer-Based Spiking Neural Networks},
  author  = {You, Z. and others},
  journal = {arXiv preprint arXiv:2406.03470},
  year    = {2024},
  url     = {https://arxiv.org/abs/2406.03470}
}
@inproceedings{spikedattention2024,
  title     = {Training-Free and Fully Spike-Driven Transformer-to-SNN Conversion with Winner-Oriented Spike Shift Softmax},
  author    = {Zhou, Zhaokun and Bu, Tong and Yao, Man and others},
  booktitle = {Advances in Neural Information Processing Systems (NeurIPS)},
  year      = {2024},
  url       = {https://nips.cc/virtual/2024/poster/94181}
}
@article{tang2024sorbet,
  title   = {Sorbet: A Neuromorphic Hardware-Compatible Transformer-Based Spiking Language Model},
  author  = {Tang, Kaiwen and Yan, Zhanglu and Wong, Weng-Fai},
  journal = {arXiv preprint arXiv:2409.15298},
  year    = {2024},
  url     = {https://arxiv.org/abs/2409.15298}
}
@article{rathi2021dietsnn,
  title   = {DIET-SNN: Direct Input Encoding for Training Low-Latency Deep Spiking Neural Networks},
  author  = {Rathi, Nitin and Roy, Kaushik and Panda, Priyadarshini},
  journal = {IEEE Transactions on Neural Networks and Learning Systems},
  volume  = {34},
  number  = {6},
  pages   = {3174--3182},
  year    = {2023},
  doi     = {10.1109/TNNLS.2021.3111897}
}
@inproceedings{rathi2020hybrid,
  title     = {Enabling Deep Spiking Neural Networks with Hybrid Conversion and Spike Timing Dependent Backpropagation},
  author    = {Rathi, Nitin and Panda, Priyadarshini and Roy, Kaushik},
  booktitle = {International Conference on Learning Representations (ICLR)},
  year      = {2020},
  url       = {https://openreview.net/forum?id=B1eLSrEtDr}
}
@inproceedings{deng2022tet,
  title     = {Temporal Efficient Training of Spiking Neural Networks via Gradient Reweighting},
  author    = {Deng, Shikuang and others},
  booktitle = {Advances in Neural Information Processing Systems (NeurIPS)},
  year      = {2022},
  url       = {https://arxiv.org/abs/2210.04195}
}
@inproceedings{hendrycks2021mmlu,
  title     = {Measuring Massive Multitask Language Understanding},
  author    = {Hendrycks, Dan and Burns, Collin and Basart, Steven and Zou, Andy and Mazeika, Mantas and Song, Dawn and Steinhardt, Jacob},
  booktitle = {International Conference on Learning Representations (ICLR)},
  year      = {2021},
  url       = {https://openreview.net/forum?id=d7KBjmI3GmQ}
}
@inproceedings{zellers2019hellaswag,
  title     = {HellaSwag: Can a Machine Really Finish Your Sentence?},
  author    = {Zellers, Rowan and Holtzman, Ari and Bisk, Yonatan and Farhadi, Ali and Choi, Yejin},
  booktitle = {Proceedings of ACL 2019},
  pages     = {4791--4800},
  year      = {2019},
  doi       = {10.18653/v1/P19-1472}
}
@article{clark2018arc,
  title   = {Think you have Solved Question Answering? Try ARC, the AI2 Reasoning Challenge},
  author  = {Clark, Peter and Cowhey, Isaac and Etzioni, Oren and Khot, Tushar and Sabharwal, Ashish and Schoenick, Carissa and Tafjord, Oyvind},
  journal = {arXiv preprint arXiv:1803.05457},
  year    = {2018},
  url     = {https://arxiv.org/abs/1803.05457}
}
@inproceedings{lin2022truthfulqa,
  title     = {TruthfulQA: Measuring How Models Mimic Human Falsehoods},
  author    = {Lin, Stephanie and Hilton, Jacob and Evans, Owain},
  booktitle = {Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics},
  pages     = {3214--3252},
  year      = {2022},
  doi       = {10.18653/v1/2022.acl-long.229}
}
@article{zhou2024spikformerv2,
  title   = {Spikformer V2: Towards Fast, Accurate, and Scalable Spiking Transformers},
  author  = {Zhou, Zhaokun and Fang, Wei and others},
  journal = {arXiv preprint arXiv:2401.02020},
  year    = {2024},
  url     = {https://arxiv.org/abs/2401.02020}
}
@article{xing2024spikelm,
  title   = {SpikeLM: Towards General Spike-Driven Language Modeling via Elastic Bi-Spiking Mechanisms},
  author  = {Xing, Tianlong and others},
  journal = {arXiv preprint arXiv:2406.03287},
  year    = {2024},
  url     = {https://arxiv.org/abs/2406.03287}
}
@article{maass1997networks,
  author    = {Maass, Wolfgang},
  title     = {Networks of Spiking Neurons: The Third Generation of Neural Network Models},
  journal   = {Neural Networks},
  volume    = {10},
  number    = {9},
  pages     = {1659--1671},
  year      = {1997},
  publisher = {Elsevier},
  doi       = {10.1016/S0893-6080(97)00011-7}
}
@inproceedings{ZhaoHuangDingYu2025_TTFSFormer,
  title        = {TTFSFormer: A TTFS-based Lossless Conversion of Spiking Transformer},
  author       = {Zhao, Lusen and Huang, Zihan and Ding, Jianhao and Yu, Zhaofei},
  booktitle    = {Proceedings of the 42nd International Conference on Machine Learning (ICML 2025)},
  year         = {2025},
  note         = {Poster},
  url          = {https://openreview.net/forum?id=mJAa823xKu}
}
@article{lecun2015deep,
  author  = {LeCun, Yann and Bengio, Yoshua and Hinton, Geoffrey},
  title   = {Deep learning},
  journal = {Nature},
  year    = {2015},
  volume  = {521},
  number  = {7553},
  pages   = {436--444},
  doi     = {10.1038/nature14539}
}
@inproceedings{Deng2023Reduce,
  title = {Reduce the Gradient Error Accumulation in Training Spiking Neural Networks},
  author = {S. Deng and et al.},
  year = {2023},
  booktitle = {Proceedings of Machine Learning Research},
}
@inproceedings{Wang2023ASGL,
  title = {Adaptive Smoothing Gradient Learning for Spiking Neural Networks},
  author = {Z. Wang and et al.},
  year = {2023},
  booktitle = {Proceedings of Machine Learning Research},
}