\section{Introduction}
\label{sec:introduction}

With the continuous expansion of parameter scales in large-scale multimodal ANNs such as language and vision models, the demand for computational resources and energy consumption is also growing exponentially. Although the transformer has become the mainstream, it still suffers from issues during the inference stage, such as redundant activations, low sparsity, high bandwidth usage, and high energy consumption. These challenges have prompted researchers to re-examine more biologically inspired, sparsity-friendly neural network architectures. Among them, SNNs, with their event-driven, asynchronous computation and naturally sparse mechanisms, are considered an important direction for building highly energy-efficient neural network systems. Especially on neuromorphic chips such as Loihi, SNNs demonstrate better energy efficiency and lower latency compared to traditional ANNs. However, limited by their information expression capability, such as the complexity of information encoding and the difficulty of training, SNNs are still mainly applied to lightweight image recognition or signal detection, and are difficult to handle large-scale sequence modeling or natural language processing.

In recent years, exploratory works such as Spikeformer and SpikeGPT have begun to attempt introducing SNNs into larger-scale modeling scenarios and have shown some potential. However, such methods often rely on lengthy time windows, soft surrogate activation functions, or approximately differentiable modules, which result in problems such as unstable training, information loss diffusion, and uncontrollable errors, making it difficult to achieve structurally consistent and high-accuracy-preserving general-purpose large-scale SNN systems.

Thus, we aim to answer a core question: is it possible to construct a high-fidelity structural mapping mechanism from ANNs to SNNs, so that as the model scales up, it can still maintain accuracy consistency, error controllability, and trainability? To this end, we propose a roadmap for gradually approaching an ideal SNN, with the core objective of maximizing the preservation of information expression capability, nonlinear modeling capability, and tunability, while controlling errors within predictable single-point regions of the network structure.

To achieve this goal, our first step is to propose Bit Spike Encoding (BSE), whose significance lies not only in replacing the encoding form but also in endowing the network with a new spiking expression language. Traditional neurons represent states through activation values, while our BSE transforms them into sparse and ordered spike sequences in the time domain, compressing expression within a fixed time window, thereby reconstructing information density from the numerical space to the spiking space. The second step is to introduce ASNC to implement nonlinear activation functions. Since activation functions are irreversible and difficult to precisely simulate, we design Adaptive Spiking Neural Codec (ASNC)  as a structural approximator. We use a piecewise adaptive strategy to fit nonlinear curves while ensuring that outputs remain in BSE encoding format, thus enabling end-to-end inference in the spiking space. Although unavoidable approximation errors are introduced here, we strictly confine them within the ASNC single-module, preventing propagation or accumulation within the network and forming a localized mechanism. On the basis of ensuring high fidelity in the forward path, we propose an STE-based approximate training scheme. Unlike previous approaches that introduced approximate non-differentiable methods at multiple structural points, we have already compressed SNN behavior into a form almost equivalent to ANNs in the first two steps, so that backpropagation only needs to approximate gradients within an extremely small error space. At this point, the introduced STE is no longer a rough substitute but a gradient stable backpropagation mechanism supported by functional consistency, thereby achieving both convergence and generalization guarantees. The key of the entire framework lies in that we no longer attempt to make low-fidelity approximations at multiple positions, but instead carefully design the system so that errors are controlled at the only controllable node within the structure, while maintaining the interpretability, tunability, and deployability of the overall system.

Within this overall framework, we systematically validated the effectiveness of our approach through extensive experiments. First, at the encoding level, BSE demonstrated orders-of-magnitude higher reconstruction fidelity compared to rate coding and TTFS under the same latency budget: for FP16, the mean squared error (MSE) was only \textbf{$1.03\times10^{-9}$}, and for FP32 it reached \textbf{$1.33\times10^{-14}$}, approaching machine precision. Second, at the non-linear stage, ASNC strictly confined approximation errors to a single local module, with an end-to-end error of only \textbf{$9.51\times10^{-7}$}, while conventional rate coding under the same condition produced an error as large as \textbf{$4.88\times10^{-1}$}, confirming our “single-point error controllability” hypothesis. Further ablation studies showed that replacing either the high-fidelity encoding or the non-linear approximation with low-fidelity alternatives caused catastrophic degradation (e.g., Rate Coding + ASNC yielded a PPL above \textbf{5000}), whereas using BSE+ASNC increased perplexity only slightly, from \textbf{$2.88\pm0.01$} to \textbf{$2.95\pm0.02$}, i.e., by about \textbf{0.07}. On large-scale models such as Llama-2 (70B), our high-fidelity ANN$\to$SNN mapping achieved less than \textbf{2\%} accuracy drop across benchmarks including MMLU, HellaSwag, ARC, and TruthfulQA, with the degradation further diminishing as model size increased—for example, the MMLU score of Llama-2 70B decreased by only \textbf{1.2\%}, indicating an emergent robustness of larger models. Finally, on Intel’s Loihi 2 neuromorphic hardware, the energy cost of a single ASNC non-linear operation was only about \textbf{0.5\%} of its SiLU counterpart on an NVIDIA A100 GPU, representing a two-order-of-magnitude reduction, while maintaining nearly identical model performance. These results collectively confirm that our roadmap achieves the threefold goals of information fidelity, controllable non-linear approximation, and stable trainability in practice.
