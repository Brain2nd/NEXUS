@misc{tay2022efficient,
      title={Efficient Transformers: A Survey}, 
      author={Yi Tay and Mostafa Dehghani and Dara Bahri and Donald Metzler},
      year={2022},
      eprint={2009.06732},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2009.06732}, 
}

@article{roy2019towards,
  author  = {Roy, Kaushik and Jaiswal, Akhilesh and Panda, Priyadarshini},
  title   = {Towards spike-based machine intelligence with neuromorphic computing},
  journal = {Nature},
  volume  = {575},
  number  = {7784},
  pages   = {607--617},
  year    = {2019},
  doi     = {10.1038/s41586-019-1677-2},
  url     = {https://doi.org/10.1038/s41586-019-1677-2},
  issn    = {1476-4687}
}

@article{davies2018loihi,
  author={Davies, Mike and Srinivasa, Narayan and Lin, Tsung-Han and Chinya, Gautham and Cao, Yongqiang and Choday, Sri Harsha and Dimou, Georgios and Joshi, Prasad and Imam, Nabil and Jain, Shweta and Liao, Yuyun and Lin, Chit-Kwan and Lines, Andrew and Liu, Ruokun and Mathaikutty, Deepak and McCoy, Steven and Paul, Arnab and Tse, Jonathan and Venkataramanan, Guruguhanathan and Weng, Yi-Hsin and Wild, Andreas and Yang, Yoonseok and Wang, Hong},
  journal={IEEE Micro}, 
  title={Loihi: A Neuromorphic Manycore Processor with On-Chip Learning}, 
  year={2018},
  volume={38},
  number={1},
  pages={82--99},
  keywords={Neurons;Computer architecture;Computational modeling;Neuromorphics;Biological neural networks;Algorithm design and analysis;neuromorphic computing;machine learning;artificial intelligence},
  doi={10.1109/MM.2018.112130359}}

@article{davies2021loihi,
  author={Davies, Mike and Wild, Andreas and Orchard, Garrick and Sandamirskaya, Yulia and Guerra, Gabriel A. Fonseca and Joshi, Prasad and Plank, Philipp and Risbud, Sumedh R.},
  journal={Proceedings of the IEEE}, 
  title={Advancing Neuromorphic Computing With Loihi: A Survey of Results and Outlook}, 
  year={2021},
  volume={109},
  number={5},
  pages={911-934},
  keywords={Computer architecture;Neurons;Computer architecture;Neuromorphic engineering;Computational modeling;Brain modeling;Biological neural networks;Neural networks;Deep learning;Computer architecture;neural network hardware;neuromorphics},
  doi={10.1109/JPROC.2021.3067593}}

@misc{orchard2021loihi2,
      title={Efficient Neuromorphic Signal Processing with Loihi 2}, 
      author={Garrick Orchard and E. Paxon Frady and Daniel Ben Dayan Rubin and Sophia Sanborn and Sumit Bam Shrestha and Friedrich T. Sommer and Mike Davies},
      year={2021},
      eprint={2111.03746},
      archivePrefix={arXiv},
      primaryClass={cs.ET},
      url={https://arxiv.org/abs/2111.03746}, 
}

@misc{zheng2021going,
      title={Going Deeper With Directly-Trained Larger Spiking Neural Networks}, 
      author={Hanle Zheng and Yujie Wu and Lei Deng and Yifan Hu and Guoqi Li},
      year={2020},
      eprint={2011.05280},
      archivePrefix={arXiv},
      primaryClass={cs.NE},
      url={https://arxiv.org/abs/2011.05280}, 
}

@misc{zhou2023spikformer,
      title={Spikformer: When Spiking Neural Network Meets Transformer}, 
      author={Zhaokun Zhou and Yuesheng Zhu and Chao He and Yaowei Wang and Shuicheng Yan and Yonghong Tian and Li Yuan},
      year={2022},
      eprint={2209.15425},
      archivePrefix={arXiv},
      primaryClass={cs.NE},
      url={https://arxiv.org/abs/2209.15425}, 
}

@misc{zhu2023spikegpt,
      title={SpikeGPT: Generative Pre-trained Language Model with Spiking Neural Networks}, 
      author={Rui-Jie Zhu and Qihang Zhao and Guoqi Li and Jason K. Eshraghian},
      year={2024},
      eprint={2302.13939},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2302.13939}, 
}

@misc{yao2023sdt,
      title={Spike-driven Transformer}, 
      author={Man Yao and Jiakui Hu and Zhaokun Zhou and Li Yuan and Yonghong Tian and Bo Xu and Guoqi Li},
      year={2023},
      eprint={2307.01694},
      archivePrefix={arXiv},
      primaryClass={cs.NE},
      url={https://arxiv.org/abs/2307.01694}, 
}

@misc{neftci2019surrogate,
      title={Surrogate Gradient Learning in Spiking Neural Networks}, 
      author={Emre O. Neftci and Hesham Mostafa and Friedemann Zenke},
      year={2019},
      eprint={1901.09948},
      archivePrefix={arXiv},
      primaryClass={cs.NE},
      url={https://arxiv.org/abs/1901.09948}, 
}

@article{wu2018stbp,
   title={Spatio-Temporal Backpropagation for Training High-Performance Spiking Neural Networks},
   volume={12},
   ISSN={1662-453X},
   url={http://dx.doi.org/10.3389/fnins.2018.00331},
   DOI={10.3389/fnins.2018.00331},
   journal={Frontiers in Neuroscience},
   publisher={Frontiers Media SA},
   author={Wu, Yujie and Deng, Lei and Li, Guoqi and Zhu, Jun and Shi, Luping},
   year={2018},
   month=may }

@misc{shrestha2018slayer,
      title={SLAYER: Spike Layer Error Reassignment in Time}, 
      author={Sumit Bam Shrestha and Garrick Orchard},
      year={2018},
      eprint={1810.08646},
      archivePrefix={arXiv},
      primaryClass={cs.NE},
      url={https://arxiv.org/abs/1810.08646}, 
}

@article{auge2021encoding,
  author  = {Auge, Daniel and Hille, Julian and Mueller, Etienne and Knoll, Alois},
  title   = {A Survey of Encoding Techniques for Signal Processing in Spiking Neural Networks},
  journal = {Neural Processing Letters},
  volume  = {53},
  number  = {6},
  pages   = {4693--4710},
  year    = {2021},
  doi     = {10.1007/s11063-021-10562-2},
  url     = {https://doi.org/10.1007/s11063-021-10562-2},
  issn    = {1573-773X}
}

@article{guo2021coding,
  title   = {Neural Coding in Spiking Neural Networks: A Comparative Study for Robust Neuromorphic Systems},
  author  = {Guo, Wenzhe  and Fouda, Mohammed E.  and Eltawil, Ahmed M.  and Salama, Khaled Nabil},
  journal = {Frontiers in Neuroscience},
  volume  = {15},
  pages   = {638474},
  year    = {2021},
  doi     = {10.3389/fnins.2021.638474},
  url     ={https://www.frontiersin.org/journals/neuroscience/articles/10.3389/fnins.2021.638474},
  issn    = {1662-453X}
}

@article{rueckauer2017conversion,
  author  = {Rueckauer, Bodo and Lungu, Iulia-Alexandra and Hu, Yuhuang and Pfeiffer, Michael and Liu, Shih-Chii},
  title   = {Conversion of Continuous-Valued Deep Networks to Efficient Event-Driven Networks for Image Classification},
  journal = {Frontiers in Neuroscience},
  volume  = {11},
  pages   = {682},
  year    = {2017},
  doi     = {10.3389/fnins.2017.00682},
  url     = {https://www.frontiersin.org/articles/10.3389/fnins.2017.00682},
  issn    = {1662-453X}
}

@article{gao2023highaccuracy,
  author  = {Gao, Haoran and He, Junxian and Wang, Haibing and Wang, Tengxiao and Zhong, Zhengqing and Yu, Jianyi and Wang, Ying and Tian, Min and Shi, Cong},
  title   = {High-Accuracy Deep ANN-to-SNN Conversion Using Quantization-Aware Training Framework and Calcium-Gated Bipolar Leaky Integrate-and-Fire Neuron},
  journal = {Frontiers in Neuroscience},
  volume  = {17},
  pages   = {1141701},
  year    = {2023},
  doi     = {10.3389/fnins.2023.1141701},
  url     = {https://www.frontiersin.org/articles/10.3389/fnins.2023.1141701},
  issn    = {1662-453X}
}

@misc{bu2023ultralow,
      title={Optimal ANN-SNN Conversion for High-accuracy and Ultra-low-latency Spiking Neural Networks}, 
      author={Tong Bu and Wei Fang and Jianhao Ding and PengLin Dai and Zhaofei Yu and Tiejun Huang},
      year={2023},
      eprint={2303.04347},
      archivePrefix={arXiv},
      primaryClass={cs.NE},
      url={https://arxiv.org/abs/2303.04347}, 
}

@article{bonilla2022ttfs,
  author  = {Bonilla, Lina and Gautrais, Jacques and Thorpe, Simon and Masquelier, Timothée},
  title   = {Analyzing Time-to-First-Spike Coding Schemes: A Theoretical Approach},
  journal = {Frontiers in Neuroscience},
  volume  = {16},
  pages   = {971937},
  year    = {2022},
  doi     = {10.3389/fnins.2022.971937},
  url     = {https://www.frontiersin.org/articles/10.3389/fnins.2022.971937},
  issn    = {1662-453X}
}

@misc{stanojevic2024ttfs,
      title={High-performance deep spiking neural networks with 0.3 spikes per neuron}, 
      author={Ana Stanojevic and Stanisław Woźniak and Guillaume Bellec and Giovanni Cherubini and Angeliki Pantazi and Wulfram Gerstner},
      year={2023},
      eprint={2306.08744},
      archivePrefix={arXiv},
      primaryClass={cs.NE},
      url={https://arxiv.org/abs/2306.08744}, 
}

@misc{you2024spikeziptf,
      title={SpikeZIP-TF: Conversion is All You Need for Transformer-based SNN}, 
      author={Kang You and Zekai Xu and Chen Nie and Zhijie Deng and Qinghai Guo and Xiang Wang and Zhezhi He},
      year={2024},
      eprint={2406.03470},
      archivePrefix={arXiv},
      primaryClass={cs.NE},
      url={https://arxiv.org/abs/2406.03470}, 
}

@inproceedings{spikedattention2024,
    title={SpikedAttention: Training-Free and Fully Spike-Driven Transformer-to-{SNN} Conversion with Winner-Oriented Spike Shift for Softmax Operation},
    author={Sangwoo Hwang and Seunghyun Lee and Dahoon Park and Donghun Lee and Jaeha Kung},
    booktitle={The Thirty-eighth Annual Conference on Neural Information Processing Systems},
    year={2024},
    url={https://openreview.net/forum?id=fs28jccJj5}
}

@misc{tang2024sorbet,
      title={Sorbet: A Neuromorphic Hardware-Compatible Transformer-Based Spiking Language Model}, 
      author={Kaiwen Tang and Zhanglu Yan and Weng-Fai Wong},
      year={2024},
      eprint={2409.15298},
      archivePrefix={arXiv},
      primaryClass={cs.NE},
      url={https://arxiv.org/abs/2409.15298}, 
}

@article{rathi2021dietsnn,
  title={DIET-SNN: Direct Input Encoding With Leakage and Threshold Optimization in Deep Spiking Neural Networks},
  author={Nitin Rathi and Kaushik Roy},
  journal={ArXiv},
  year={2020},
  volume={abs/2008.03658},
  url={https://api.semanticscholar.org/CorpusID:221132082}
}

@misc{rathi2020hybrid,
      title={Enabling Deep Spiking Neural Networks with Hybrid Conversion and Spike Timing Dependent Backpropagation}, 
      author={Nitin Rathi and Gopalakrishnan Srinivasan and Priyadarshini Panda and Kaushik Roy},
      year={2020},
      eprint={2005.01807},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2005.01807}, 
}

@misc{deng2022tet,
      title={Temporal Efficient Training of Spiking Neural Network via Gradient Re-weighting}, 
      author={Shikuang Deng and Yuhang Li and Shanghang Zhang and Shi Gu},
      year={2022},
      eprint={2202.11946},
      archivePrefix={arXiv},
      primaryClass={cs.NE},
      url={https://arxiv.org/abs/2202.11946}, 
}

@misc{hendrycks2021mmlu,
      title={Measuring Massive Multitask Language Understanding}, 
      author={Dan Hendrycks and Collin Burns and Steven Basart and Andy Zou and Mantas Mazeika and Dawn Song and Jacob Steinhardt},
      year={2021},
      eprint={2009.03300},
      archivePrefix={arXiv},
      primaryClass={cs.CY},
      url={https://arxiv.org/abs/2009.03300}, 
}

@misc{zellers2019hellaswag,
      title={HellaSwag: Can a Machine Really Finish Your Sentence?}, 
      author={Rowan Zellers and Ari Holtzman and Yonatan Bisk and Ali Farhadi and Yejin Choi},
      year={2019},
      eprint={1905.07830},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/1905.07830}, 
}

@misc{clark2018arc,
      title={Think you have Solved Question Answering? Try ARC, the AI2 Reasoning Challenge}, 
      author={Peter Clark and Isaac Cowhey and Oren Etzioni and Tushar Khot and Ashish Sabharwal and Carissa Schoenick and Oyvind Tafjord},
      year={2018},
      eprint={1803.05457},
      archivePrefix={arXiv},
      primaryClass={cs.AI},
      url={https://arxiv.org/abs/1803.05457}, 
}

@misc{lin2022truthfulqa,
      title={TruthfulQA: Measuring How Models Mimic Human Falsehoods}, 
      author={Stephanie Lin and Jacob Hilton and Owain Evans},
      year={2022},
      eprint={2109.07958},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2109.07958}, 
}

@misc{zhou2024spikformerv2,
      title={Spikformer V2: Join the High Accuracy Club on ImageNet with an SNN Ticket}, 
      author={Zhaokun Zhou and Kaiwei Che and Wei Fang and Keyu Tian and Yuesheng Zhu and Shuicheng Yan and Yonghong Tian and Li Yuan},
      year={2024},
      eprint={2401.02020},
      archivePrefix={arXiv},
      primaryClass={cs.NE},
      url={https://arxiv.org/abs/2401.02020}, 
}

@inproceedings{wang2023stsa,
  title     = {Spatial-Temporal Self-Attention for Asynchronous Spiking Neural Networks},
  author    = {Wang, X. and others},
  booktitle = {Proceedings of the Thirty-Second International Joint Conference on Artificial Intelligence (IJCAI)},
  year      = {2023},
  url       = {https://www.ijcai.org/proceedings/2023/118}
}

@article{xing2025spikellm,
  title   = {A Spiking Large Language Model},
  author  = {Xing, Tianlong and others},
  journal = {arXiv preprint arXiv:2410.11456},
  year    = {2025},
  url     = {https://arxiv.org/abs/2410.11456}
}

@misc{xing2024spikelm,
      title={SpikeLM: Towards General Spike-Driven Language Modeling via Elastic Bi-Spiking Mechanisms}, 
      author={Xingrun Xing and Zheng Zhang and Ziyi Ni and Shitao Xiao and Yiming Ju and Siqi Fan and Yequan Wang and Jiajun Zhang and Guoqi Li},
      year={2024},
      eprint={2406.03287},
      archivePrefix={arXiv},
      primaryClass={cs.NE},
      url={https://arxiv.org/abs/2406.03287}, 
}

@article{maass1997networks,
  author  = {Maass, Wolfgang},
  title   = {Networks of Spiking Neurons: The Third Generation of Neural Network Models},
  journal = {Neural Networks},
  volume  = {10},
  number  = {9},
  pages   = {1659--1671},
  year    = {1997},
  doi     = {10.1016/S0893-6080(97)00011-7},
  url     = {https://www.sciencedirect.com/science/article/pii/S0893608097000117},
  issn    = {0893-6080}
}

@inproceedings{ZhaoHuangDingYu2025_TTFSFormer,
    title={{TTFSF}ormer: A {TTFS}-based Lossless Conversion of Spiking Transformer},
    author={Lusen Zhao and Zihan Huang and Jianhao Ding and Zhaofei Yu},
    booktitle={Forty-second International Conference on Machine Learning},
    year={2025},
    url={https://openreview.net/forum?id=mJAa823xKu}
}

@article{lecun2015deep,
  author  = {LeCun, Yann and Bengio, Yoshua and Hinton, Geoffrey},
  title   = {Deep Learning},
  journal = {Nature},
  volume  = {521},
  number  = {7553},
  pages   = {436--444},
  year    = {2015},
  doi     = {10.1038/nature14539},
  url     = {https://doi.org/10.1038/nature14539},
  issn    = {1476-4687}
}

@inproceedings{Deng2023Reduce,
  author    = {Deng, Shikuang and Lin, Hao and Li, Yuhang and Gu, Shi},
  title     = {Surrogate Module Learning: Reduce the Gradient Error Accumulation in Training Spiking Neural Networks},
  booktitle = {Proceedings of the 40th International Conference on Machine Learning (ICML)},
  series    = {Proceedings of Machine Learning Research},
  volume    = {202},
  pages     = {7645--7657},
  year      = {2023},
  publisher = {PMLR},
  url       = {https://proceedings.mlr.press/v202/deng23c.html}
}

@inproceedings{Wang2023ASGL,
  author    = {Wang, Ziming and Jiang, Runhao and Lian, Shuang and Yan, Rui and Tang, Huajin},
  title     = {Adaptive Smoothing Gradient Learning for Spiking Neural Networks},
  booktitle = {Proceedings of the 40th International Conference on Machine Learning (ICML)},
  series    = {Proceedings of Machine Learning Research},
  volume    = {202},
  pages     = {35798--35816},
  year      = {2023},
  publisher = {PMLR},
  url       = {https://proceedings.mlr.press/v202/wang23j.html}
}


@book{gersho1992vector,
  author    = {Gersho, Allen and Gray, Robert M.},
  title     = {Vector Quantization and Signal Compression},
  publisher = {Kluwer Academic Publishers},
  year      = {1992},
  address   = {Boston, MA},
  isbn      = {978-0-7923-9181-4 / 0-7923-9181-0},
  doi       = {10.1007/978-1-4615-3626-0}
}

@inproceedings{he2024understanding,
  title     = {Understanding and Minimising Outlier Features in Transformer Training},
  author    = {Bobby He and Lorenzo Noci and Daniele Paliotta and Imanol Schlag and Thomas Hofmann},
  booktitle = {The Thirty-eighth Annual Conference on Neural Information Processing Systems},
  year      = {2024},
  url       = {https://openreview.net/forum?id=npJQ6qS4bg}
}

@inproceedings{lin2024duquant,
  title     = {DuQuant: Distributing Outliers via Dual Transformation Makes Stronger Quantized {LLM}s},
  author    = {Haokun Lin and Haobo Xu and Yichen Wu and Jingzhi Cui and Yingtao Zhang and Linzhan Mou and Linqi Song and Zhenan Sun and Ying Wei},
  booktitle = {The Thirty-eighth Annual Conference on Neural Information Processing Systems},
  year      = {2024},
  url       = {https://openreview.net/forum?id=mp8u2Pcmqz}
}


@article{xing2024spikellm,
  title={SpikeLLM: Scaling up Spiking Neural Network to Large Language Models via Saliency-based Spiking},
  author={Xing, Xingrun and Zheng, Boyan and Li, Zheng and Liu, Tianao and Yao, Yuyao and Zheng, Zhiyu and Liu, Deng-Ping and Hu, Xiaopeng and Xu, Zhi-Quan},
  journal={arXiv preprint arXiv:2407.04752},
  year={2024}
}
